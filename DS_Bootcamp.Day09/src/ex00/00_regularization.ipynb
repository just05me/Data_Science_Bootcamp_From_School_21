{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 09. Exercise 00\n",
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read the file `dayofweek.csv` that you used in the previous day to a dataframe.\n",
    "2. Using `train_test_split` with parameters `test_size=0.2`, `random_state=21` get `X_train`, `y_train`, `X_test`, `y_test`. Use the additional parameter `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/dayofweek.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numTrials</th>\n",
       "      <th>hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>uid_user_0</th>\n",
       "      <th>uid_user_1</th>\n",
       "      <th>uid_user_10</th>\n",
       "      <th>uid_user_11</th>\n",
       "      <th>uid_user_12</th>\n",
       "      <th>uid_user_13</th>\n",
       "      <th>uid_user_14</th>\n",
       "      <th>...</th>\n",
       "      <th>labname_lab02</th>\n",
       "      <th>labname_lab03</th>\n",
       "      <th>labname_lab03s</th>\n",
       "      <th>labname_lab05s</th>\n",
       "      <th>labname_laba04</th>\n",
       "      <th>labname_laba04s</th>\n",
       "      <th>labname_laba05</th>\n",
       "      <th>labname_laba06</th>\n",
       "      <th>labname_laba06s</th>\n",
       "      <th>labname_project1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.788667</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756764</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.724861</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.692958</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.661055</td>\n",
       "      <td>-2.562352</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>-0.629151</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>-0.597248</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>-0.565345</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>-0.533442</td>\n",
       "      <td>0.945382</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1686 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      numTrials      hour  dayofweek  uid_user_0  uid_user_1  uid_user_10  \\\n",
       "0     -0.788667 -2.562352          4           0           0            0   \n",
       "1     -0.756764 -2.562352          4           0           0            0   \n",
       "2     -0.724861 -2.562352          4           0           0            0   \n",
       "3     -0.692958 -2.562352          4           0           0            0   \n",
       "4     -0.661055 -2.562352          4           0           0            0   \n",
       "...         ...       ...        ...         ...         ...          ...   \n",
       "1681  -0.533442  0.945382          3           0           0            0   \n",
       "1682  -0.629151  0.945382          3           0           1            0   \n",
       "1683  -0.597248  0.945382          3           0           1            0   \n",
       "1684  -0.565345  0.945382          3           0           1            0   \n",
       "1685  -0.533442  0.945382          3           0           1            0   \n",
       "\n",
       "      uid_user_11  uid_user_12  uid_user_13  uid_user_14  ...  labname_lab02  \\\n",
       "0               0            0            0            0  ...              0   \n",
       "1               0            0            0            0  ...              0   \n",
       "2               0            0            0            0  ...              0   \n",
       "3               0            0            0            0  ...              0   \n",
       "4               0            0            0            0  ...              0   \n",
       "...           ...          ...          ...          ...  ...            ...   \n",
       "1681            0            0            0            0  ...              0   \n",
       "1682            0            0            0            0  ...              0   \n",
       "1683            0            0            0            0  ...              0   \n",
       "1684            0            0            0            0  ...              0   \n",
       "1685            0            0            0            0  ...              0   \n",
       "\n",
       "      labname_lab03  labname_lab03s  labname_lab05s  labname_laba04  \\\n",
       "0                 0               0               0               0   \n",
       "1                 0               0               0               0   \n",
       "2                 0               0               0               0   \n",
       "3                 0               0               0               0   \n",
       "4                 0               0               0               0   \n",
       "...             ...             ...             ...             ...   \n",
       "1681              0               0               0               0   \n",
       "1682              0               0               0               0   \n",
       "1683              0               0               0               0   \n",
       "1684              0               0               0               0   \n",
       "1685              0               0               0               0   \n",
       "\n",
       "      labname_laba04s  labname_laba05  labname_laba06  labname_laba06s  \\\n",
       "0                   0               0               0                0   \n",
       "1                   0               0               0                0   \n",
       "2                   0               0               0                0   \n",
       "3                   0               0               0                0   \n",
       "4                   0               0               0                0   \n",
       "...               ...             ...             ...              ...   \n",
       "1681                0               0               0                1   \n",
       "1682                0               0               0                1   \n",
       "1683                0               0               0                1   \n",
       "1684                0               0               0                1   \n",
       "1685                0               0               0                1   \n",
       "\n",
       "      labname_project1  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  \n",
       "...                ...  \n",
       "1681                 0  \n",
       "1682                 0  \n",
       "1683                 0  \n",
       "1684                 0  \n",
       "1685                 0  \n",
       "\n",
       "[1686 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('dayofweek', axis=1)\n",
    "y = data['dayofweek']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=45, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logreg regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `random_state=21`, `fit_intercept=False`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model\n",
    "\n",
    "\n",
    "The result of the code where you trained and evaluated the baseline model should be exactly like this (use `%%time` to get the info about how long it took to run the cell):\n",
    "\n",
    "```\n",
    "train -  0.62902   |   valid -  0.59259\n",
    "train -  0.64633   |   valid -  0.62963\n",
    "train -  0.63479   |   valid -  0.56296\n",
    "train -  0.65622   |   valid -  0.61481\n",
    "train -  0.63397   |   valid -  0.57778\n",
    "train -  0.64056   |   valid -  0.59259\n",
    "train -  0.64138   |   valid -  0.65926\n",
    "train -  0.65952   |   valid -  0.56296\n",
    "train -  0.64333   |   valid -  0.59701\n",
    "train -  0.63674   |   valid -  0.62687\n",
    "Average accuracy on crossval is 0.60165\n",
    "Std is 0.02943\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=45, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval(model, X, y, n_splits=10):\n",
    "    train_scores = []\n",
    "    valid_scores = []\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "    for train, valid in skf.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train], X.iloc[valid]\n",
    "        \n",
    "        y_train, y_valid = y.iloc[train], y.iloc[valid]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        y_valid_pred = model.predict(X_valid)\n",
    "        \n",
    "        train_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "        \n",
    "        valid_scores.append(accuracy_score(y_valid, y_valid_pred))\n",
    "\n",
    "    for i in range(len(train_scores)):\n",
    "        print(f'train - {train_scores[i]:.5f} | valid - {valid_scores[i]:.5f}')\n",
    "        \n",
    "    print(f'Average accuracy on crossval is {np.mean(valid_scores):.5f}')\n",
    "    print(f'Std is {np.std(valid_scores):.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.63809 | valid - 0.54074\n",
      "train - 0.63891 | valid - 0.60741\n",
      "train - 0.61500 | valid - 0.66667\n",
      "train - 0.62242 | valid - 0.60000\n",
      "train - 0.63314 | valid - 0.66667\n",
      "train - 0.63149 | valid - 0.54074\n",
      "train - 0.64221 | valid - 0.60741\n",
      "train - 0.63397 | valid - 0.51852\n",
      "train - 0.62603 | valid - 0.67164\n",
      "train - 0.62932 | valid - 0.61194\n",
      "Average accuracy on crossval is 0.60317\n",
      "Std is 0.05276\n",
      "CPU times: user 6.18 s, sys: 19.9 ms, total: 6.2 s\n",
      "Wall time: 920 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of penalty: `none`, `l1`, `l2` – you can change the values of solver too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 μs, sys: 1e+03 ns, total: 15 μs\n",
      "Wall time: 136 μs\n",
      "train - 0.68178 | valid - 0.57037\n",
      "train - 0.67189 | valid - 0.61481\n",
      "train - 0.66777 | valid - 0.65926\n",
      "train - 0.68261 | valid - 0.65185\n",
      "train - 0.66117 | valid - 0.69630\n",
      "train - 0.66777 | valid - 0.55556\n",
      "train - 0.68838 | valid - 0.62222\n",
      "train - 0.66694 | valid - 0.59259\n",
      "train - 0.65321 | valid - 0.67910\n",
      "train - 0.66722 | valid - 0.61940\n",
      "Average accuracy on crossval is 0.62615\n",
      "Std is 0.04346\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "lr = LogisticRegression(\n",
    "    penalty=None,\n",
    "    max_iter=1000,\n",
    "    random_state=21,\n",
    "    fit_intercept=False\n",
    ")\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.62655 | valid - 0.54815\n",
      "train - 0.61830 | valid - 0.61481\n",
      "train - 0.59934 | valid - 0.64444\n",
      "train - 0.60841 | valid - 0.57037\n",
      "train - 0.61253 | valid - 0.64444\n",
      "train - 0.61418 | valid - 0.52593\n",
      "train - 0.62572 | valid - 0.60741\n",
      "train - 0.61418 | valid - 0.52593\n",
      "train - 0.60297 | valid - 0.63433\n",
      "train - 0.61120 | valid - 0.57463\n",
      "Average accuracy on crossval is 0.58904\n",
      "Std is 0.04403\n",
      "CPU times: user 386 ms, sys: 7.59 ms, total: 393 ms\n",
      "Wall time: 411 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=21, \n",
    "                        fit_intercept=False, \n",
    "                        solver='liblinear', \n",
    "                        penalty='l1')\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.61665 | valid - 0.54815\n",
      "train - 0.61500 | valid - 0.60741\n",
      "train - 0.59604 | valid - 0.64444\n",
      "train - 0.60923 | valid - 0.56296\n",
      "train - 0.61418 | valid - 0.64444\n",
      "train - 0.60841 | valid - 0.54074\n",
      "train - 0.62325 | valid - 0.57778\n",
      "train - 0.60429 | valid - 0.49630\n",
      "train - 0.60544 | valid - 0.64179\n",
      "train - 0.60791 | valid - 0.56716\n",
      "Average accuracy on crossval is 0.58312\n",
      "Std is 0.04775\n",
      "CPU times: user 283 ms, sys: 1.07 ms, total: 284 ms\n",
      "Wall time: 288 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n",
      "/home/just05me/pandas/PandasVenv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=21, \n",
    "                        fit_intercept=False, \n",
    "                        solver='liblinear', \n",
    "                        penalty='l2')\n",
    "crossval(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SVM regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `probability=True`, `kernel='linear'`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=21, probability=True, kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.69909 | valid - 0.61481\n",
      "train - 0.68013 | valid - 0.68148\n",
      "train - 0.67766 | valid - 0.68889\n",
      "train - 0.68755 | valid - 0.65185\n",
      "train - 0.68425 | valid - 0.68148\n",
      "train - 0.69580 | valid - 0.62222\n",
      "train - 0.69580 | valid - 0.66667\n",
      "train - 0.68838 | valid - 0.58519\n",
      "train - 0.67957 | valid - 0.70149\n",
      "train - 0.69275 | valid - 0.66418\n",
      "Average accuracy on crossval is 0.65583\n",
      "Std is 0.03535\n",
      "CPU times: user 6.87 s, sys: 23.8 ms, total: 6.89 s\n",
      "Wall time: 7.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.69909 | valid - 0.61481\n",
      "train - 0.68013 | valid - 0.68148\n",
      "train - 0.67766 | valid - 0.68889\n",
      "train - 0.68755 | valid - 0.65185\n",
      "train - 0.68425 | valid - 0.68148\n",
      "train - 0.69580 | valid - 0.62222\n",
      "train - 0.69580 | valid - 0.66667\n",
      "train - 0.68838 | valid - 0.58519\n",
      "train - 0.67957 | valid - 0.70149\n",
      "train - 0.69275 | valid - 0.66418\n",
      "Average accuracy on crossval is 0.65583\n",
      "Std is 0.03535\n",
      "CPU times: user 7.13 s, sys: 11.8 ms, total: 7.14 s\n",
      "Wall time: 7.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC(random_state=21, probability=True, kernel='linear', C=1)\n",
    "crossval(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.69827 | valid - 0.60000\n",
      "train - 0.72135 | valid - 0.69630\n",
      "train - 0.68673 | valid - 0.67407\n",
      "train - 0.71393 | valid - 0.67407\n",
      "train - 0.70569 | valid - 0.68889\n",
      "train - 0.74856 | valid - 0.64444\n",
      "train - 0.73949 | valid - 0.69630\n",
      "train - 0.70157 | valid - 0.59259\n",
      "train - 0.71911 | valid - 0.73881\n",
      "train - 0.70675 | valid - 0.65672\n",
      "Average accuracy on crossval is 0.66622\n",
      "Std is 0.04253\n",
      "CPU times: user 7 s, sys: 3.69 ms, total: 7.01 s\n",
      "Wall time: 7.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC(random_state=21, probability=True, kernel='linear', C=2)\n",
    "crossval(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.74031 | valid - 0.65185\n",
      "train - 0.74691 | valid - 0.71111\n",
      "train - 0.73537 | valid - 0.71852\n",
      "train - 0.73372 | valid - 0.68889\n",
      "train - 0.74031 | valid - 0.70370\n",
      "train - 0.78071 | valid - 0.65185\n",
      "train - 0.76917 | valid - 0.71852\n",
      "train - 0.71146 | valid - 0.60000\n",
      "train - 0.74053 | valid - 0.75373\n",
      "train - 0.73888 | valid - 0.67910\n",
      "Average accuracy on crossval is 0.68773\n",
      "Std is 0.04171\n",
      "CPU times: user 8.52 s, sys: 16.7 ms, total: 8.54 s\n",
      "Wall time: 8.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svm = SVC(random_state=21, probability=True, kernel='linear', C=4)\n",
    "crossval(svm, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameter `max_depth=10` and `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=21, max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.81286 | valid - 0.79259\n",
      "train - 0.82358 | valid - 0.75556\n",
      "train - 0.81121 | valid - 0.75556\n",
      "train - 0.83430 | valid - 0.76296\n",
      "train - 0.81863 | valid - 0.75556\n",
      "train - 0.82110 | valid - 0.68889\n",
      "train - 0.84089 | valid - 0.77037\n",
      "train - 0.82358 | valid - 0.72593\n",
      "train - 0.84267 | valid - 0.82836\n",
      "train - 0.81137 | valid - 0.76866\n",
      "Average accuracy on crossval is 0.76044\n",
      "Std is 0.03493\n",
      "CPU times: user 203 ms, sys: 4.01 ms, total: 207 ms\n",
      "Wall time: 213 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the cells below try different values of the parameter `max_depth`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.81286 | valid - 0.79259\n",
      "train - 0.82358 | valid - 0.75556\n",
      "train - 0.81121 | valid - 0.75556\n",
      "train - 0.83430 | valid - 0.76296\n",
      "train - 0.81863 | valid - 0.75556\n",
      "train - 0.82110 | valid - 0.68889\n",
      "train - 0.84089 | valid - 0.77037\n",
      "train - 0.82358 | valid - 0.72593\n",
      "train - 0.84267 | valid - 0.82836\n",
      "train - 0.81137 | valid - 0.76866\n",
      "Average accuracy on crossval is 0.76044\n",
      "Std is 0.03493\n",
      "CPU times: user 213 ms, sys: 10 μs, total: 213 ms\n",
      "Wall time: 217 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=10)\n",
    "crossval(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.99340 | valid - 0.90370\n",
      "train - 0.99093 | valid - 0.91111\n",
      "train - 0.99176 | valid - 0.88889\n",
      "train - 0.98763 | valid - 0.89630\n",
      "train - 0.99258 | valid - 0.88889\n",
      "train - 0.99340 | valid - 0.87407\n",
      "train - 0.99505 | valid - 0.85926\n",
      "train - 0.99505 | valid - 0.89630\n",
      "train - 0.99259 | valid - 0.94030\n",
      "train - 0.99176 | valid - 0.85821\n",
      "Average accuracy on crossval is 0.89170\n",
      "Std is 0.02329\n",
      "CPU times: user 203 ms, sys: 1.99 ms, total: 205 ms\n",
      "Wall time: 208 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=20)\n",
    "crossval(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.88148\n",
      "train - 1.00000 | valid - 0.87407\n",
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.88889\n",
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.85926\n",
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.94030\n",
      "train - 1.00000 | valid - 0.86567\n",
      "Average accuracy on crossval is 0.88949\n",
      "Std is 0.02133\n",
      "CPU times: user 198 ms, sys: 1.03 ms, total: 199 ms\n",
      "Wall time: 199 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=40)\n",
    "crossval(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'criterion': 'gini', 'max_depth': 25, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best score: 0.8842764697783286\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    \"max_depth\": range(10, 40),\n",
    "    'min_samples_split': range(2, 4),\n",
    "    'min_samples_leaf': range(1, 4),\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=21)\n",
    "\n",
    "gs = GridSearchCV(estimator=tree, param_grid=params, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {gs.best_params_}')\n",
    "print(f'Best score: {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.99423 | valid - 0.88889\n",
      "train - 0.99258 | valid - 0.88889\n",
      "train - 0.99340 | valid - 0.86667\n",
      "train - 0.99093 | valid - 0.88889\n",
      "train - 0.99423 | valid - 0.88889\n",
      "train - 0.99670 | valid - 0.88889\n",
      "train - 0.99670 | valid - 0.85926\n",
      "train - 0.99918 | valid - 0.89630\n",
      "train - 0.99506 | valid - 0.93284\n",
      "train - 0.99423 | valid - 0.85075\n",
      "Average accuracy on crossval is 0.88502\n",
      "Std is 0.02160\n",
      "CPU times: user 198 ms, sys: 1.03 ms, total: 199 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(random_state=21, max_depth=21, min_samples_split=2, min_samples_leaf=1)\n",
    "crossval(tree, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Default regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a baseline model with the only parameters `n_estimators=50`, `max_depth=14`, `random_state=21`.\n",
    "2. Use stratified K-fold cross-validation with `10` splits to evaluate the accuracy of the model.\n",
    "3. The format of the result of the code where you trained and evaluated the baseline model should be similar to what you have got for the logreg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=21, n_estimators=50, max_depth=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.97032 | valid - 0.88148\n",
      "train - 0.96785 | valid - 0.88889\n",
      "train - 0.97197 | valid - 0.88148\n",
      "train - 0.96290 | valid - 0.86667\n",
      "train - 0.96950 | valid - 0.93333\n",
      "train - 0.96208 | valid - 0.85926\n",
      "train - 0.96867 | valid - 0.86667\n",
      "train - 0.96702 | valid - 0.85185\n",
      "train - 0.95717 | valid - 0.90299\n",
      "train - 0.97199 | valid - 0.88806\n",
      "Average accuracy on crossval is 0.88207\n",
      "Std is 0.02249\n",
      "CPU times: user 2.34 s, sys: 18 ms, total: 2.36 s\n",
      "Wall time: 2.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "crossval(forest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Optimizing regularization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In the new cells try different values of the parameters `max_depth` and `n_estimators`.\n",
    "2. As a bonus, play with other regularization parameters trying to find the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 0.97279 | valid - 0.91111\n",
      "train - 0.97527 | valid - 0.90370\n",
      "train - 0.97857 | valid - 0.88889\n",
      "train - 0.96702 | valid - 0.86667\n",
      "train - 0.97115 | valid - 0.93333\n",
      "train - 0.97197 | valid - 0.86667\n",
      "train - 0.97197 | valid - 0.86667\n",
      "train - 0.96785 | valid - 0.85926\n",
      "train - 0.96623 | valid - 0.91791\n",
      "train - 0.97199 | valid - 0.89552\n",
      "Average accuracy on crossval is 0.89097\n",
      "Std is 0.02427\n",
      "CPU times: user 4.55 s, sys: 29.1 ms, total: 4.58 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(random_state=21, n_estimators=100, max_depth=14)\n",
    "crossval(forest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 1.00000 | valid - 0.93333\n",
      "train - 1.00000 | valid - 0.91852\n",
      "train - 1.00000 | valid - 0.90370\n",
      "train - 1.00000 | valid - 0.94815\n",
      "train - 1.00000 | valid - 0.93333\n",
      "train - 1.00000 | valid - 0.88889\n",
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.91852\n",
      "train - 1.00000 | valid - 0.94030\n",
      "train - 1.00000 | valid - 0.90299\n",
      "Average accuracy on crossval is 0.91840\n",
      "Std is 0.01904\n",
      "CPU times: user 4.89 s, sys: 18.1 ms, total: 4.91 s\n",
      "Wall time: 4.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(random_state=21, n_estimators=100, max_depth=30)\n",
    "crossval(forest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 35, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score: 0.9132039102299325\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': range(100, 250, 30),\n",
    "    'max_depth': range(20, 40, 5),\n",
    "    'min_samples_split': range(2, 4),\n",
    "    'min_samples_leaf': range(1, 4),\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=RandomForestClassifier(random_state=21), \n",
    "                  param_grid=params, \n",
    "                  scoring='accuracy', \n",
    "                  cv=5, \n",
    "                  n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best params: {gs.best_params_}')\n",
    "print(f'Best score: {gs.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - 1.00000 | valid - 0.93333\n",
      "train - 1.00000 | valid - 0.91111\n",
      "train - 1.00000 | valid - 0.88889\n",
      "train - 1.00000 | valid - 0.94074\n",
      "train - 1.00000 | valid - 0.93333\n",
      "train - 1.00000 | valid - 0.89630\n",
      "train - 1.00000 | valid - 0.90370\n",
      "train - 1.00000 | valid - 0.91111\n",
      "train - 1.00000 | valid - 0.94030\n",
      "train - 1.00000 | valid - 0.91045\n",
      "Average accuracy on crossval is 0.91693\n",
      "Std is 0.01774\n",
      "CPU times: user 9.44 s, sys: 31 ms, total: 9.47 s\n",
      "Wall time: 9.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "forest = RandomForestClassifier(random_state=21, n_estimators=190, max_depth=35)\n",
    "crossval(forest, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose the best model and use it to make predictions for the test dataset.\n",
    "2. Calculate the final accuracy.\n",
    "3. Analyze: for which weekday your model makes the most errors (in % of the total number of samples of that class in your test dataset).\n",
    "4. Save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349112426035503"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=21, \n",
    "                                n_estimators=190, \n",
    "                                max_depth=35)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = forest.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        27\n",
      "           1       0.89      0.93      0.91        55\n",
      "           2       0.97      0.93      0.95        30\n",
      "           3       0.97      0.95      0.96        80\n",
      "           4       1.00      1.00      1.00        21\n",
      "           5       0.94      0.93      0.93        54\n",
      "           6       0.89      0.94      0.92        71\n",
      "\n",
      "    accuracy                           0.93       338\n",
      "   macro avg       0.94      0.93      0.94       338\n",
      "weighted avg       0.94      0.93      0.94       338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, y_pred, labels=range(0, 7))\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  2,  0,  0,  0,  0,  2],\n",
       "       [ 2, 51,  1,  0,  0,  0,  1],\n",
       "       [ 0,  1, 28,  0,  0,  0,  1],\n",
       "       [ 0,  2,  0, 76,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0, 21,  0,  0],\n",
       "       [ 0,  0,  0,  2,  0, 50,  2],\n",
       "       [ 0,  1,  0,  0,  0,  3, 67]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(matrix, annot=True, cmap=\"Blues\", center=0, cbar=True)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/model.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(forest, '../data/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PandasVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
